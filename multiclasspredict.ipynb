{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import (roc_curve, auc, roc_auc_score, \n",
    "                             precision_recall_fscore_support)\n",
    "from sklearn.model_selection import (train_test_split, GridSearchCV, \n",
    "                                     KFold, StratifiedKFold, cross_val_score, \n",
    "                                     cross_val_predict)\n",
    "from sklearn.preprocessing import label_binarize, LabelEncoder, LabelBinarizer\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import (SelectKBest, f_classif, VarianceThreshold, \n",
    "                                       SelectFromModel)\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.datasets import load_iris\n",
    "import itertools\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import copy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OvO and OvR prediction function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, LabelBinarizer\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_predict, GridSearchCV\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, auc\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "import numpy as np\n",
    "import itertools\n",
    "\n",
    "def split_classes(X, y):\n",
    "    return {\n",
    "        (c1, c2): (X[(y == c1) | (y == c2)], y[(y == c1) | (y == c2)])\n",
    "        for c1, c2 in itertools.combinations(np.unique(y), 2)\n",
    "    }\n",
    "\n",
    "def ovo_and_ova_multiclass_auc(X, y, base_clf, p_grid, random_state):\n",
    "    results = {}\n",
    "    le = LabelEncoder()\n",
    "    y = le.fit_transform(y)\n",
    "    class_names = le.classes_\n",
    "\n",
    "    # Stratified K-Folds\n",
    "    inner_cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=random_state)\n",
    "    outer_cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=random_state)\n",
    "\n",
    "    ####################\n",
    "    # One-vs-Rest Classification\n",
    "    ####################\n",
    "    print(\"Performing One vs Rest classification\")\n",
    "    ovr_clf = GridSearchCV(\n",
    "        estimator=OneVsRestClassifier(base_clf),\n",
    "        param_grid=p_grid,\n",
    "        cv=inner_cv,\n",
    "        scoring=\"roc_auc_ovr\"\n",
    "    )\n",
    "    y_score = cross_val_predict(ovr_clf, X, y, cv=outer_cv, method=\"predict_proba\")\n",
    "\n",
    "    # Calculate AUC for each class\n",
    "    y_bin = LabelBinarizer().fit_transform(y)\n",
    "    ovr_auc = roc_auc_score(y_bin, y_score, multi_class=\"ovr\", average=None)\n",
    "    for idx, auc_val in enumerate(ovr_auc):\n",
    "        print(f\"AUC for class '{class_names[idx]}': {auc_val:.4f}\")\n",
    "        results[f\"{class_names[idx]} vs Rest\"] = auc_val\n",
    "\n",
    "    # Calculate macro and micro AUC for OvR\n",
    "    macro_ovr_auc = roc_auc_score(y_bin, y_score, multi_class=\"ovr\", average=\"macro\")\n",
    "    micro_ovr_auc = roc_auc_score(y_bin, y_score, multi_class=\"ovr\", average=\"micro\")\n",
    "    results[\"OvR Macro AUC\"] = macro_ovr_auc\n",
    "    results[\"OvR Micro AUC\"] = micro_ovr_auc\n",
    "    print(f\"Macro AUC (OvR): {macro_ovr_auc:.4f}\")\n",
    "    print(f\"Micro AUC (OvR): {micro_ovr_auc:.4f}\")\n",
    "\n",
    "    ####################\n",
    "    # One-vs-One Classification\n",
    "    ####################\n",
    "    print(\"Performing One vs One classification\")\n",
    "    ovo_auc = {}\n",
    "    class_pairs = split_classes(X, y)\n",
    "\n",
    "    for (c1, c2), (X_subset, y_subset) in class_pairs.items():\n",
    "        ovo_clf = GridSearchCV(\n",
    "            estimator=base_clf,\n",
    "            param_grid={k.replace(\"estimator__\", \"\"): v for k, v in p_grid.items()},\n",
    "            cv=inner_cv,\n",
    "            scoring=\"roc_auc\"\n",
    "        )\n",
    "        y_score = cross_val_predict(ovo_clf, X_subset, y_subset, cv=outer_cv, method=\"predict_proba\")\n",
    "        y_binary = (y_subset == c2).astype(int)\n",
    "        fpr, tpr, _ = roc_curve(y_binary, y_score[:, 1])\n",
    "        auc_val = auc(fpr, tpr)\n",
    "\n",
    "        # Decode labels\n",
    "        results[f\"{le.inverse_transform([c1])[0]} vs {le.inverse_transform([c2])[0]}\"] = auc_val\n",
    "        ovo_auc[(c1, c2)] = auc_val\n",
    "\n",
    "    # Calculate macro and micro AUC for OvO\n",
    "    macro_ovo_auc = np.mean(list(ovo_auc.values()))  # Macro: Average AUC over all class pairs\n",
    "    micro_ovo_auc = roc_auc_score(y, cross_val_predict(base_clf, X, y, cv=outer_cv, method=\"predict_proba\"), multi_class=\"ovo\", average=\"micro\")  # Direct micro AUC for OvO\n",
    "    results[\"OvO Macro AUC\"] = macro_ovo_auc\n",
    "    results[\"OvO Micro AUC\"] = micro_ovo_auc\n",
    "    print(f\"Macro AUC (OvO): {macro_ovo_auc:.4f}\")\n",
    "    print(f\"Micro AUC (OvO): {micro_ovo_auc:.4f}\")\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "import pandas as pd\n",
    "\n",
    "# Generate a synthetic dataset\n",
    "X, y = make_classification(\n",
    "    n_samples=150,  # Number of samples\n",
    "    n_features=1000,   # Total number of features\n",
    "    n_informative=20,  # Number of informative features\n",
    "    n_redundant=200,    # Number of redundant features\n",
    "    n_classes=3,       # Number of target classes\n",
    "    random_state=42    # For reproducibility\n",
    ")\n",
    "\n",
    "# Convert to DataFrame\n",
    "X = pd.DataFrame(X)\n",
    "y = pd.Series(y, name=\"target\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV for seed 1 and 10 features\n",
      "Performing One vs Rest classification\n",
      "AUC for class '0': 0.7946\n",
      "AUC for class '1': 0.7396\n",
      "AUC for class '2': 0.7322\n",
      "Macro AUC (OvR): 0.7555\n",
      "Micro AUC (OvR): 0.7548\n",
      "Performing One vs One classification\n"
     ]
    }
   ],
   "source": [
    "seed_results = {}\n",
    "\n",
    "seeds = [1,2,3]\n",
    "ks = [10,100]\n",
    "\n",
    "for seed in seeds:\n",
    "    ks_results = {}\n",
    "    for k in ks:\n",
    "\n",
    "        print(f\"CV for seed {seed} and {k} features\")\n",
    "\n",
    "        # Define the classifier\n",
    "        classifier = RandomForestClassifier(random_state=seed)\n",
    "\n",
    "        # Create a Random Forest Classifier\n",
    "        rf = RandomForestClassifier(n_estimators=100, random_state=seed)\n",
    "\n",
    "        # Create a SelectFromModel using the Random Forest Classifier\n",
    "        selector = SelectFromModel(rf, max_features = k)\n",
    "\n",
    "        # Create a pipeline with feature selection and classification\n",
    "        pipeline = Pipeline(steps=[\n",
    "            ('feature_selection', selector),\n",
    "            ('classification', rf)\n",
    "        ])\n",
    "\n",
    "        # Parameter grid for RandomForestClassifier\n",
    "        p_grid = {\n",
    "            \"estimator__classification__n_estimators\": [100],          # Number of trees in the forest\n",
    "            \"estimator__classification__max_features\": [\"sqrt\"],       # Feature selection strategy\n",
    "            \"estimator__classification__criterion\": [\"entropy\"],       # Split criterion\n",
    "            \"estimator__classification__min_samples_leaf\": [3],        # Minimum samples per leaf\n",
    "        }\n",
    "\n",
    "        ###########################\n",
    "            \n",
    "        results = ovo_and_ova_multiclass_auc(X,y,pipeline, p_grid, random_state=seed)\n",
    "\n",
    "        print(results)\n",
    "\n",
    "        ks_results[k] = results\n",
    "\n",
    "    seed_results[seed] = copy.copy(ks_results)\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   0 vs Rest  1 vs Rest  2 vs Rest  0 vs 1  0 vs 2  1 vs 2\n",
      "Seed Features (k)                                                         \n",
      "1    2                   1.0     0.9858     0.9858     1.0     1.0  0.9736\n",
      "     3                   1.0     0.9858     0.9858     1.0     1.0  0.9736\n",
      "2    2                   1.0     0.9894     0.9894     1.0     1.0  0.9768\n",
      "     3                   1.0     0.9894     0.9894     1.0     1.0  0.9768\n",
      "3    2                   1.0     0.9787     0.9687     1.0     1.0  0.9512\n",
      "     3                   1.0     0.9787     0.9687     1.0     1.0  0.9512\n"
     ]
    }
   ],
   "source": [
    "# Flatten the nested dictionary into a DataFrame\n",
    "df = pd.DataFrame(\n",
    "    {(outer_key, inner_key): values for outer_key, inner_dict in seed_results.items() for inner_key, values in inner_dict.items()}\n",
    ").T\n",
    "\n",
    "# Set multi-level index names for clarity\n",
    "df.index.names = ['Seed', 'Features (k)']\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
